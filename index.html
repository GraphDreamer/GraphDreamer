<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="GraphDreamer generates multi-object compositional 3D scenes from scene graph prompts.">
  <meta name="keywords" content="GraphDreamer, G-Dreamer, GT3D">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', '');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/GGGHSL">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>

<!-- Author + Links -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ggghsl.github.io/GGGWebsite">Gege Gao</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://wyliu.com">Weiyang Liu</a><sup>1,4</sup>,</span>
            <span class="author-block">
              <a href="https://apchenstu.github.io">Anpei Chen</a><sup>2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cvlibs.net">Andreas Geiger</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://is.mpg.de/~bs">Bernhard Schölkopf</a><sup>1,2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Max Planck Institute for Intelligent Systems,</span>
            <span class="author-block"><sup>2</sup>ETH Zürich,</span>
            <span class="author-block"><sup>3</sup>University of Tübinge,</span>
            <span class="author-block"><sup>4</sup>University of Cambridge,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v="
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span title="Coming soon!">Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content has-text-centered">
        <!-- <embed src="./static/images/teaser.pdf" width="1047px" height="auto"> -->
        <img src="./static/images/teaser.jpg"
          class="interpolation-image"
          alt="teaser image."/>
      </div>
      <h2 class="subtitle has-text-centered">
        GraphDreamer takes scene graphs as input and generates object compositional 3D scenes.
      </h2>
    </div>
  </div>
</section>


<!-- Videos Figure3 -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">        
        
        <div class="item item-figure3-row1">
          <video poster="" id="figure3-row1" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure3_row1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure3-row2">
          <video poster="" id="figure3-row2" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure3_row2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure3-row3">
          <video poster="" id="figure3-row3" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure3_row3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure3-row4">
          <video poster="" id="figure3-row4" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure3_row4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure3-row5">
          <video poster="" id="figure3-row5" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure3_row5.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure3-row6">
          <video poster="" id="figure3-row6" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure3_row6.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure3-row7">
          <video poster="" id="figure3-row7" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure3_row7.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure3-row8">
          <video poster="" id="figure3-row8" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure3_row8.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Abstract + Video + Pipeline -->
<section class="section">
  <div class="container is-max-desktop">
    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present <span class="gdreamer">GraphDreamer</span>, the first framework capable of generating compositional 3D scenes from scene graphs, where objects are represented as nodes and their interactions as edges. 
          </p>
          <p>
            As pretrained text-to-image diffusion models become increasingly powerful, recent efforts have been made to distill knowledge from these text-to-image pretrained models for optimizing a text-guided 3D model. Most of the existing methods generate a holistic 3D model from a plain text input. This can be problematic when the text describes a complex scene with multiple objects, because the vectorized text embeddings are inherently unable to capture a complex description with multiple entities and relationships. Holistic 3D modeling of the entire scene further prevents accurate grounding of text entities and concepts. 
          </p>
          <p>
            Our method makes better use of the pretrained text-to-image diffusion model by exploiting node and edge information in scene graphs, and is able to fully disentangle different objects without image-level supervision. To facilitate modeling of object-wise relationships, we use signed distance fields as representation and impose a constraint to avoid inter-penetration of objects. To avoid manual scene graph creation, we design a text prompt for ChatGPT to generate scene graphs based on text inputs. We conduct both qualitative and quantitative experiments to validate the effectiveness of GraphDreamer in generating high-fidelity compositional 3D scenes with disentangled object entities.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->

    <!-- Pipeline. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <!-- <div class="content has-text-centered">
          <embed src="./static/images/paper_pipeline.pdf" width="404px" height="auto">
        </div> -->
        <!-- <embed src="./static/images/paper_pipeline.pdf" width="404px" height="auto"> -->
        <img src="./static/images/paper_pipeline.jpg"
          class="interpolation-image"
          alt="paper pipeline."/>
        
        <div class="content has-text-justified">
          <p>GraphDreamer decomposes the scene graph into global, node-wise and edge-wise text description, and represents and optimizes the SDF-based objects individually with identity-aware object fields.</p>
        </div>
      </div>
    </div>
    <!--/ Pipeline. -->
  </div>
</section>


<!-- Videos Figure5 -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Results:</h2>
      <h2 class="subtitle has-text-justified">
        Leveraging scene graphs for compositional text grounding.
      </h2>
    </div>
    <div class="container">
      <div id="widget-carousel" class="carousel widget-carousel">        
        <div class="item item-figure5-1">
          <video poster="" id="figure5-1" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure5_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure5-2">
          <video poster="" id="figure5-2" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure5_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure5-3">
          <video poster="" id="figure5-3" autoplay controls muted loop playsinline>
          <!-- width="100%" -->
            <source src="./static/videos/figure5_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure5-4">
          <video poster="" id="figure5-4" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure5_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure5-5">
          <video poster="" id="figure5-5" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure5_5.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-figure5-6">
          <video poster="" id="figure5-6" autoplay controls muted loop playsinline>
            <source src="./static/videos/figure5_6.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Inverse Semantics. -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- <h2 class="title is-3">Inverse Semantics</h2>
    <p>
      We present a new paradigm of semantic reconstruction with GPT4V-guided GraphDreamer.
    </p> -->

    <!-- Inverse. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Inverse Semantics: </h2>
        <h2 class="subtitle has-text-justified">
          We also present a new paradigm of semantic reconstruction with GPT4V-guided GraphDreamer.
        </h2><br/>

        <!-- 3 Nodes. -->
        <h3 class="title is-4">Extract scene graph from images</h3>
        <div class="content has-text-justified">
          <p>
            Using GraphDreamer, we can inverse the semantics in a given image into a 3D scene, by extracting a scene graph directly from an input image with GPT4V, restricting the nodes present to the most salient ones.
          </p>
        </div>
        <div class="content has-text-centered">
          <!-- <iframe id="inverse-3n" src="./static/images/inverse_3n.pdf" type="application/pdf" height="100%" width="100%">
          </iframe> -->
          <img src="./static/images/inverse_3n.jpg"
               class="interpolation-image"
               alt="Interpolate inverse example image 1."/>
        </div>

        <!-- <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div> -->
        <br/>
        <!--/ 3 Nodes. -->

        <!-- 5 Nodes. -->
        <h3 class="title is-4">Identify object centers for initialization</h3>
        <div class="content has-text-justified">
          <p>
            To inverse more complex semantics with more salient nodes in an image, we can ask GPT to provide with center coordinates for each object and initialize the SDF-based objects as spheres centered at these coordinates.
          </p>
        </div>
        <div class="content has-text-centered">
          <!-- <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video> -->
          <!-- <iframe id="inverse-5n" src="./static/images/inverse_5n.pdf" type="application/pdf" height="100%" width="100%">
          </iframe> -->
          <img src="./static/images/inverse_5n.jpg"
               class="interpolation-image"
               alt="Interpolate inverse example image 2."/>
        </div>
        <!--/ 5 Nodes. -->

      </div>
    </div>
    <!--/ Inverse. -->

  </div>
</section>
<!--/ Inverse Semantics. -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{gege2023graphdreamer,
  author    = {Gao, Gege and Liu, Weiyang and Chen, Anpei and Geiger, Andreas and Schölkopf, Bernhard},
  title     = {GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs},
  journal   = {arXiv},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/graphdreamer_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/GGGHSL" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
